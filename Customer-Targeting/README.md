A propensity model was built that will be used to predict, whether a given customer will respond to a specified promotion or not. To develop this model several datasets will be used, including customer transaction history for all customers between March 2012 and February 2013. As well as two promotions datasets, one given a subset of customers during March 2013, including whether they responded. Since we know the value of the action, this dataset will be used to train our propensity model. The second promotions dataset was given to a different subset of customers during April 2014 and will be used as our blind test data to assess the true accuracy of our model.  
It is important to ensure the model doesn’t overfit the training data and instead can identify a good customer signature, that will be used to make an accurate prediction of a customer’s action to a promotion. This idea of a customer signature is especially critical since only 8 out of the 15 previous promotions training the model will be used in the 17 test promotions. As well, there is not a single customer in common between the training set and the validation set. This means that over 50% of the time, the model must predict whether a customer, who it has never seen before, will respond to a new promotion it never encountered. When making the prediction, the model will thus rely on the customer’s signature, and ideally, look at how similar customers responded to similar or the same promotions to predict how this new customer will react. Thus to create this customer signature it was essential to focus most of the time on feature engineering. 

The final model used XGBoost and after hyperparameter tuning using grid search cross-validation, the model was able to achieve an AUC of 0.69 and an accuracy of 81% on the validation set.

Data from the following kaggle competition: https://www.kaggle.com/competitions/acquire-valued-shoppers-challenge/overview
